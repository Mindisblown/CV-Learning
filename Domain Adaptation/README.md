# KL散度

​		源于信息论，信息论主要研究如何量化数据中的信息，最重要的信息度量单位是熵。熵值并没有给出压缩数据到最小熵值的方法，即如何编码数据才能达到最优（存储空间最优），熵的主要作用是告诉我们最优编码信息方案的理论下界（存储空间），以及度量数据信息量的一种方式。熵从另一个层面也说明了有多少信息蕴含在数据之中，用一个带参数的概率分布来近似替代原始数据分布的时候，熵可以计算到底损失了多少信息。

​		散度并非距离，他不符合对称性。用p近似q和用q近似p算出的值是不同的，也表明二者损失的信息是不一致的。

# 协变量偏移Covariate Shift

​		数据随着外部因素变化而变化。

# GRL梯度反转

​		将梯度乘上一个负数，那么GRL层前后的网络他们的目标就是相反的，实现对抗的目的。

# 联合概率分布

​		两个或两个以上随机随机变量联合地概率分布情况。

# 边缘概率

​		在知道联合概率分布后，其中某几个变量子集的概率分布被称为边缘概率分布。

# 条件概率

​		在给定某个事件后，其他事件发生的概率，例如在已知今天多云的条件下下雨的概率就是条件概率。